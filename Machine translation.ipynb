{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made this project to get more familiar with NLP and learn something about Machine translation, as well as practice working with torch and torchtext. The ultimate goal was to create a machine translation pipeline, going from raw data to trained algorithm, and adjust it according to currently used data / architecture. This notebook puts all the modules together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't present all the code here. For anyone curious, I encourage you to check out the source code. Set up GPU is assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prerequisities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "WMT14\n",
    "- download https://1drv.ms/f/s!AiQ5a2cXVytTlkZD0HQn5FdGRgB2\n",
    "- move to data/WMT14\n",
    "\n",
    "Multi30k\n",
    "- download https://1drv.ms/f/s!AiQ5a2cXVytTllU4usk93QbPGv1s\n",
    "- move to data/Multi30k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I highly recommend setting up a conda environment before installing packages.\n",
    "- navigate to root\n",
    "- pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\anaconda3\\envs\\machine_translation\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "d:\\programs\\anaconda3\\envs\\machine_translation\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "d:\\programs\\anaconda3\\envs\\machine_translation\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "d:\\programs\\anaconda3\\envs\\machine_translation\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.data.loader import load_multi30k, load_WMT14\n",
    "from src.data.raw_to_proc import proc_WMT14, proc_multi30k, create_WMT14_samp\n",
    "from src.models.lstm_rnn import SimpleEncoder,SimpleEncoderVLS,SimpleDecoder\n",
    "from src.models import fit,translate\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Restructuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Although the downloads provide both raw and processed datasets, I would like to share functions used on raw data to create the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proc_multi30k()\n",
    "proc_WMT14()\n",
    "create_WMT14_samp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These functions are used to get access to 3 dataset loaders - WMT14 with batch size 1, Multi30k with batch size 1 and Multi30k with custom batch size (I chose 32). My implementation doesn't support other batch sizes for WMT14. The two variants of Multi30k will be used to showcase certain features of batching when using RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "WMT14 dataset is czech-english, Multi30k is german-english. We are going to translate to english in both cases, hence TRG corresponds to english vocab and SRC corresponds to either czech or german vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iter, valid_iter, SRC, TRG = load_WMT14(1)\n",
    "src, trg = 'src','trg'\n",
    "ds_name = 'WMT14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iter, valid_iter, SRC, TRG = load_multi30k(1)\n",
    "src, trg = 'de','en'\n",
    "ds_name = 'Multi30k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iter, valid_iter, SRC, TRG = load_multi30k(32)\n",
    "src, trg = 'de','en'\n",
    "ds_name = 'Multi30k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's set some useful variables too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_words_src = len(SRC.vocab)\n",
    "n_words_trg = len(TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pad_src_id = SRC.vocab.stoi['<pad>']\n",
    "pad_trg_id = TRG.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trg_sos_id = TRG.vocab.stoi['<SOS>']\n",
    "trg_eos_id = TRG.vocab.stoi['<EOS>']\n",
    "src_eos_id = SRC.vocab.stoi['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_len = len(train_iter)\n",
    "val_len = len(valid_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name = 'LSTM_RNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setting some basic parameters for network - sizes of embedding vectors and hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedding_size_src = 300\n",
    "embedding_size_trg = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_hidden_src = 200\n",
    "n_hidden_trg = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the most basic type of model we will use. For practical reasons, we are going to treat encoder and decoder separately. The pair below is only capable of single-sequence input processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc = SimpleEncoder(n_words_src,embedding_size_src,n_hidden_src).cuda()\n",
    "dec = SimpleDecoder(n_words_trg,embedding_size_trg,n_hidden_trg).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The pair below is able to work with batch of VLS (variable length sequences). Because we are working with RNNs, parallel computation isn't as straightforward as in the case of other architectures, especially in our case with big amount of short sequences of variable lengths. The real dealbreaker here is the fact that we have pairs of sequences, meaning we can't simply join together the ones with least padding. As a solution, I have tried to implement PyTorch PackedSequence objects, with at least some succes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc = SimpleEncoderVLS(n_words_src,embedding_size_src,n_hidden_src,pad_src_id).cuda()\n",
    "dec = SimpleDecoder(n_words_trg,embedding_size_trg,n_hidden_trg).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The hyperparameters used can be changed as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setting up some training parameters - optimizers, learning rate, loss function, number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt_enc = optim.SGD(enc.parameters(),5e-2)\n",
    "opt_dec = optim.SGD(dec.parameters(),5e-2)\n",
    "loss_fn = F.nll_loss\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you haven't gone for VLS model, the first fit function should be used. If using VLS model, the second function should be used. In order to manipulate length of training you can change the end_train and end_val parameters. I suggest using print_every size 5 times smaller than end_train. It's also good idea to set teacher_forcing to zero in the later stages of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "Train: 5.931363204918285 \n",
      "Valid: 5.800572688036626 \n",
      "\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "Train: 5.524714240933409 \n",
      "Valid: 5.603949924506764 \n",
      "\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "Train: 5.448665373396166 \n",
      "Valid: 5.522936438569928 \n",
      "\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "Train: 5.422433366869936 \n",
      "Valid: 5.481520067347159 \n",
      "\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "100.0% done\n",
      "Train: 5.207599790969698 \n",
      "Valid: 5.445132262635939 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit.lstm_rnn(enc,dec,train_iter,valid_iter,epochs,opt_enc,opt_dec,loss_fn,n_words_trg, trg_sos_id,\n",
    "             src, trg, ds_name, model_name, end_train=int(train_len/10),end_val=int(val_len/10),\n",
    "             print_every=int(train_len/(10*5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6% done\n",
      "1.1% done\n",
      "1.7% done\n",
      "2.2% done\n",
      "2.8% done\n",
      "3.3% done\n",
      "3.9% done\n",
      "4.4% done\n",
      "5.0% done\n",
      "5.5% done\n",
      "6.1% done\n",
      "6.6% done\n",
      "7.2% done\n",
      "7.7% done\n",
      "8.3% done\n",
      "8.8% done\n",
      "9.4% done\n",
      "9.9% done\n",
      "10.5% done\n",
      "11.0% done\n",
      "11.6% done\n",
      "12.2% done\n",
      "12.7% done\n",
      "13.3% done\n",
      "13.8% done\n",
      "14.4% done\n",
      "14.9% done\n",
      "15.5% done\n",
      "16.0% done\n",
      "16.6% done\n",
      "17.1% done\n",
      "17.7% done\n",
      "18.2% done\n",
      "18.8% done\n",
      "19.3% done\n",
      "19.9% done\n",
      "Train: 5.073108215524693 \n",
      "Valid: 5.1813329735187565 \n",
      "\n",
      "20.4% done\n",
      "21.0% done\n",
      "21.5% done\n",
      "22.1% done\n",
      "22.7% done\n",
      "23.2% done\n",
      "23.8% done\n",
      "24.3% done\n",
      "24.9% done\n",
      "25.4% done\n",
      "26.0% done\n",
      "26.5% done\n",
      "27.1% done\n",
      "27.6% done\n",
      "28.2% done\n",
      "28.7% done\n",
      "29.3% done\n",
      "29.8% done\n",
      "30.4% done\n",
      "30.9% done\n",
      "31.5% done\n",
      "32.0% done\n",
      "32.6% done\n",
      "33.1% done\n",
      "33.7% done\n",
      "34.3% done\n",
      "34.8% done\n",
      "35.4% done\n",
      "35.9% done\n",
      "36.5% done\n",
      "37.0% done\n",
      "37.6% done\n",
      "38.1% done\n",
      "38.7% done\n",
      "39.2% done\n",
      "39.8% done\n",
      "Train: 5.2609340686990755 \n",
      "Valid: 5.150072846749817 \n",
      "\n",
      "40.3% done\n",
      "40.9% done\n",
      "41.4% done\n",
      "42.0% done\n",
      "42.5% done\n",
      "43.1% done\n",
      "43.6% done\n",
      "44.2% done\n",
      "44.8% done\n",
      "45.3% done\n",
      "45.9% done\n",
      "46.4% done\n",
      "47.0% done\n",
      "47.5% done\n",
      "48.1% done\n",
      "48.6% done\n",
      "49.2% done\n",
      "49.7% done\n",
      "50.3% done\n",
      "50.8% done\n",
      "51.4% done\n",
      "51.9% done\n",
      "52.5% done\n",
      "53.0% done\n",
      "53.6% done\n",
      "54.1% done\n",
      "54.7% done\n",
      "55.2% done\n",
      "55.8% done\n",
      "56.4% done\n",
      "56.9% done\n",
      "57.5% done\n",
      "58.0% done\n",
      "58.6% done\n",
      "59.1% done\n",
      "59.7% done\n",
      "Train: 5.161083303316675 \n",
      "Valid: 5.251803461951439 \n",
      "\n",
      "60.2% done\n",
      "60.8% done\n",
      "61.3% done\n",
      "61.9% done\n",
      "62.4% done\n",
      "63.0% done\n",
      "63.5% done\n",
      "64.1% done\n",
      "64.6% done\n",
      "65.2% done\n",
      "65.7% done\n",
      "66.3% done\n",
      "66.9% done\n",
      "67.4% done\n",
      "68.0% done\n",
      "68.5% done\n",
      "69.1% done\n",
      "69.6% done\n",
      "70.2% done\n",
      "70.7% done\n",
      "71.3% done\n",
      "71.8% done\n",
      "72.4% done\n",
      "72.9% done\n",
      "73.5% done\n",
      "74.0% done\n",
      "74.6% done\n",
      "75.1% done\n",
      "75.7% done\n",
      "76.2% done\n",
      "76.8% done\n",
      "77.3% done\n",
      "77.9% done\n",
      "78.5% done\n",
      "79.0% done\n",
      "79.6% done\n",
      "Train: 5.275578630090964 \n",
      "Valid: 5.228825560723893 \n",
      "\n",
      "80.1% done\n",
      "80.7% done\n",
      "81.2% done\n",
      "81.8% done\n",
      "82.3% done\n",
      "82.9% done\n",
      "83.4% done\n",
      "84.0% done\n",
      "84.5% done\n",
      "85.1% done\n",
      "85.6% done\n",
      "86.2% done\n",
      "86.7% done\n",
      "87.3% done\n",
      "87.8% done\n",
      "88.4% done\n",
      "89.0% done\n",
      "89.5% done\n",
      "90.1% done\n",
      "90.6% done\n",
      "91.2% done\n",
      "91.7% done\n",
      "92.3% done\n",
      "92.8% done\n",
      "93.4% done\n",
      "93.9% done\n",
      "94.5% done\n",
      "95.0% done\n",
      "95.6% done\n",
      "96.1% done\n",
      "96.7% done\n",
      "97.2% done\n",
      "97.8% done\n",
      "98.3% done\n",
      "98.9% done\n",
      "99.4% done\n",
      "Train: 5.17569672820544 \n",
      "Valid: 5.021304919262125 \n",
      "\n",
      "100.0% done\n"
     ]
    }
   ],
   "source": [
    "fit.lstm_rnn_vls(enc,dec,train_iter,valid_iter,epochs,opt_enc,opt_dec,loss_fn,n_words_trg, trg_sos_id,\n",
    "                 pad_src_id, pad_trg_id,end_train=int(train_len/5),end_val=int(val_len/5),\n",
    "                 print_every=int(train_len/(5*5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fit functions automatically save progress along with printing losses (see source code of fit functions), but these functions can be used to manually save / load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path_Multi30k = 'models/LSTM_RNN/Multi30k/'\n",
    "model_path_WMT14 = 'models/LSTM_RNN/WMT14/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Loading / saving Multi30k models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc.load_state_dict(torch.load(f'{model_path_Multi30k}enc.pt'))\n",
    "dec.load_state_dict(torch.load(f'{model_path_Multi30k}dec.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), f'{model_path_Multi30k}enc.pt')\n",
    "torch.save(dec.state_dict(), f'{model_path_Multi30k}dec.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Loading / saving WMT14 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc.load_state_dict(torch.load(f'{model_path_WMT14}enc.pt'))\n",
    "dec.load_state_dict(torch.load(f'{model_path_WMT14}dec.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), f'{model_path_WMT14}enc.pt')\n",
    "torch.save(dec.state_dict(), f'{model_path_WMT14}dec.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example of loading 3rd iteration of Multi30k model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc.load_state_dict(torch.load(f'{model_path_Multi30k}enc_3.pt'))\n",
    "dec.load_state_dict(torch.load(f'{model_path_Multi30k}dec_3.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We won't dig deep into the model's workings / performance. For now, we will only look at examples of the model's translations. This will give us some insight into it's capabilities and we will also be able to better interpret the results given by applying custom metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To get new example, simply reload the line below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rand_ex = next(iter(valid_iter))\n",
    "ex_src,ex_trg = getattr(rand_ex,src),getattr(rand_ex,trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These two cells show what we are going to translate and it's human translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mehrere',\n",
       " 'menschen',\n",
       " 'stehen',\n",
       " 'in',\n",
       " 'der',\n",
       " 'dämmerung',\n",
       " 'in',\n",
       " 'der',\n",
       " 'nähe',\n",
       " 'einiger',\n",
       " 'bäume',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[SRC.vocab.itos[x] for x in ex_src[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>',\n",
       " 'several',\n",
       " 'people',\n",
       " 'are',\n",
       " 'standing',\n",
       " 'near',\n",
       " 'trees',\n",
       " 'at',\n",
       " 'dusk',\n",
       " '<EOS>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TRG.vocab.itos[x] for x in ex_trg[:,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we use our model to translate the sentence. Choose appropriate translate function (Multi30k, Multi30k_VLS and WMT14 respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sent_ids = translate.Multi30k(enc,dec,trg_sos_id,trg_eos_id,ex_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sent_ids = translate.Multi30k_VLS(enc,dec,trg_sos_id,trg_eos_id,pad_src_id,ex_src[:,0][:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sent_ids = translate.WMT14(enc,dec,trg_sos_id,trg_eos_id,ex_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can take a look at the sentence our model created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['several', 'people', 'are', 'people', 'in', 'near', 'a', 'a', 'a', '<EOS>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TRG.vocab.itos[x] for x in sent_ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
